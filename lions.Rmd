---
title: "Lion_Occupancy"
author: "Maggie Klope"
date: "7/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rgbif)
library(maptools)
library(dismo)
library(rgeos)
library(viridis)
library(scrubr)
library(raster)
library(DHARMa)

# download lion data (will take a while)
gbif_lion <- occ_data(scientificName = "Panthera leo", 
                      hasCoordinate = TRUE, 
                      continent = "Africa")

```

### Getting coordinates
```{r}
# get the columns that matter for mapping and cleaning the occurrence data:
myspecies_coords <- gbif_lion$data %>% 
  dplyr::select(decimalLongitude, decimalLatitude, occurrenceStatus, coordinateUncertaintyInMeters, institutionCode, references) %>% 
  filter(occurrenceStatus == "PRESENT")

head(myspecies_coords) # 496 records

```


### simple map of occurence data
```{r}
# downloads map data
(data("wrld_simpl"))

# plot
plot(wrld_simpl, 
     xlim = range(myspecies_coords$decimalLongitude),
     ylim = range(myspecies_coords$decimalLatitude), 
     axes = TRUE, 
     col = "light yellow"
     )
box()
# add the points
points(myspecies_coords$decimalLongitude, myspecies_coords$decimalLatitude, col = 'blue', pch = 20, cex = 0.75)
# plot points again to add a border, for better visibility
points(myspecies_coords$decimalLongitude, myspecies_coords$decimalLatitude, col = 'red', cex = 0.75)

```


### Cleaning Data
```{r}
# remove duplicates
cleaned_1 <- myspecies_coords %>% 
  distinct(decimalLatitude, decimalLatitude, .keep_all = TRUE) # 337 remaining

cleaned_2 <- coord_incomplete(coord_imprecise(coord_impossible(coord_unlikely(cleaned_1)))) %>% 
  rename(lat = decimalLatitude) %>% 
  rename(long = decimalLongitude)

# nrow(cleaned_2) #330

lat_long <- cleaned_2 %>% 
  dplyr::select(lat, long)

```

### Absence and Background Points
```{r}
# downloading worldclim data
r <- getData("worldclim",var="bio",res=10)
r <- r[[c(1,12)]] # selecting bioclim 1-12
raster <- r[[1]] # selectiong bioclim 1

# viewing the raster
# plot(raster)

# cropping raster
e <- extent(
  min(cleaned_2$long)-1,
  max(cleaned_2$long)+1,
  min(cleaned_2$lat)-1,
  max(cleaned_2$lat)+1
)

mask <- crop(raster, e)

# select 500 random points
# set seed to assure that the examples will always have the same random sample.
set.seed(1963)
bg <- randomPoints(mask, 500)
plot(bg)

# convert species data to spatial layer
coordinates(cleaned_2) <- ~long+lat
projection(cleaned_2) <- CRS('+proj=longlat +datum=WGS84')

# reprojecting world map
projection(wrld_simpl) <- CRS('+proj=longlat +datum=WGS84')

# create circles using arbitrary radius of 50 km
x <- circles(cleaned_2, d = 50000, lonlat = TRUE)
pol <- polygons(x)
plot(pol)
plot(wrld_simpl, add=TRUE)

# # first method
# # take random sample of points within the polygons, only want one point per grid
# # sample randomly from all circles
# samp1 <- spsample(pol, 250, type = 'random', iter = 25)
# ## Warning in proj4string(obj): CRS object has comment, which is lost in output
# # get unique cells
# cells <- cellFromXY(mask, samp1)
# length(cells)
# ## [1] 250
# cells <- unique(cells)
# length(cells)
# ## [1] 161
# xy <- xyFromCell(mask, cells)
# 
# #plot
# plot(pol, axes=TRUE)
# points(xy, cex=0.75, pch=20, col='blue')

#second method
# extract cell numbers for the circles
v <- raster::extract(mask, x@polygons, cellnumbers = T)
# use rbind to combine the elements in list v
v <- do.call(rbind, v)
# get unique cell numbers from which you could sample
v <- unique(v[,1])
head(v)
## [1] 15531 15717 17581 17582 17765 17767

# to display the results
# m <- mask
# plot(m)
m[] <- NA
m[v] <- 1
plot(m, ext = extent(x@polygons) + 10)
plot(x@polygons, add = T)

```

### Environmental Data
```{r}
path <- file.path(system.file(package = "dismo"))
files <- list.files(path, pattern='grd$', full.names=TRUE )

clim_data <- getData("worldclim", var = "bio", res = 10)

# making sure everything lines up
plot(clim_data, 1, 
     xlim = range(myspecies_coords$decimalLongitude),
     ylim = range(myspecies_coords$decimalLatitude)
     )
plot(x@polygons, add = T)
points(cleaned_2$long,cleaned_2$lat, col='orange', pch=20, cex=0.75)

```

### Extracting from Raster
```{r}
# checking that crs are the same
crs(r)
crs(cleaned_2)

r <- getData("worldclim",var = "bio",res = 10)

presvals <- raster::extract(r, cleaned_2)
presvals # what are the NA values?

# extract for 500 random background points
# random set of points for this example
r_cropped <- extent(
  min(cleaned_2$long)-1,
  max(cleaned_2$long)+1,
  min(cleaned_2$lat)-1,
  max(cleaned_2$lat)+1
)

r_2 <- crop(r, r_cropped )

set.seed(0)
backgr <- randomPoints(r_2, 500)
plot(backgr)
absvals <- raster::extract(r_2, backgr)
absvals <- as.matrix(absvals)
pb <- c(rep(1, nrow(presvals)), rep(0, nrow(absvals)))
# pb <- as.matrix(pb)
# pb <- c(rep(1, nrow(presvals)), rep(0, length(absvals)))
sdmdata <- data.frame(cbind(pb, rbind(presvals, absvals))) %>% 
  drop_na()
# sdmdata[,'biome'] = as.factor(sdmdata[,'biome'])
head(sdmdata)


```

# model fitting
```{r}
pvals <- presvals

# first model using glm()function
# presence/absence as a model of bio predictors
m1 <- glm(pb ~ bio1 + bio5 + bio12, data = sdmdata) # shouldn't this be a binomial glm with presence/absence?

summary(m1)

# using simulateResiduals from the DHARMa package to look @ model fit
simulateResiduals(m1, plot = TRUE) # horrible model fit

# second model using bioclim function
bc <- bioclim(presvals[,c('bio1', 'bio5', 'bio12')])
class(bc)
pairs(bc)

```

# model predictions
```{r}
# making dataframe for predicted/future climate data
bio1 = c(40, 150, 200)
bio5 = c(60, 115, 290)
bio12 = c(600, 1600, 1700)
pd = data.frame(cbind(bio1, bio5, bio12))
pd

# predictions with first model
predict(m1, pd)

# predictions with second model
predict(bc, pd)

```

# model evaluation

AUC = Area Under the REceiver Operator Curve

- A measure of rank-correlation. 
- High values = high predicted suitability

## using example data, normally distributed, with presence data having higher mean than absence
```{r}

# p = presence, represents the predicted value of 50 known locations where species is present
p <- rnorm(50, mean = 0.7, sd = 0.3)

# a = absence, represents predicted value of 50 known locations where species is absent
a <- rnorm(50, mean = 0.4, sd = 0.4)

# plotting
par(mfrow = c(1, 2)) # setting graphics parameters
plot(sort(p), col='red', pch=21)
points(sort(a), col='blue', pch=24)
legend(1, 0.95 * max(a,p), c('presence', 'absence'),
          pch=c(21,24), col=c('red', 'blue'))
comb <- c(p,a)
group <- c(rep('presence', length(p)), rep('absence', length(a)))
boxplot(comb~group, col=c('blue', 'red'))

# computing correlation coefficient and AUC
group <-  c(rep(1, length(p)), rep(0, length(a)))

cor.test(comb, group)$estimate

mv <- wilcox.test(p,a)
auc <- as.numeric(mv$statistic) / (length(p) * length(a))
auc

# can also be calculated with the ROCR package
e <- evaluate(p=p, a=a)
class(e)
e

par(mfrow=c(1, 2))
density(e)
boxplot(e, col=c('blue', 'red'))

```

## using our data
```{r}

# divide our data into two sets, one for training and one for evaluating
samp <- sample(nrow(sdmdata), round(0.75 * nrow(sdmdata))) # saving 75% of data

# creating training dataset
traindata <- sdmdata[samp,] # using that 75% of the main data
traindata <- traindata[traindata[,1] == 1, 2:9] # saving where first column = 1, filtering to just columns 2:9

# creating test data
testdata <- sdmdata[-samp,] # using all other data (remaining ~25%)

# using the bioclim algorithm on training data
bc <- bioclim(traindata)

# predicting with test data
e <- dismo::evaluate(testdata[testdata == 1,], testdata[testdata == 0,], bc)
e

plot(e, 'ROC')

# k-fold data partitioning
# save presence and background points
pres <- sdmdata[sdmdata[,1] == 1, 2:9]
back <- sdmdata[sdmdata[,1] == 0, 2:9]

# partitioning the presence data into 5 groups (background data only used for model testing, does not need to be partitioned)
k <- 5 # setting number of groups
group <- kfold(pres, k) # using kfold: each record in data gets randomly assigned to group 1-5

# testing model 5 times, each run corresponds to one group of data
e <- list() # create empty list that data saves into inside the for loop

for (i in 1:k) {
    train <- pres[group != i,] # trains on all the other groups
    test <- pres[group == i,] # tests on the selected group
    bc <- bioclim(train) # runs bioclim model
    e[[i]] <- evaluate(p=test, a=back, bc) #saves model evaluation into e
}

# now we can extract information from e
# getting AUC values
auc <- sapply(e, function(x){x@auc})
auc
mean(auc)

# getting spec_sens = "maximum of the sum of the sensitivity (true positive rate) and specificity (true negative rate)” threshold
# this is sometimes uses as a threshold for setting cells to presence or absence
sapply( e, function(x){ threshold(x)['spec_sens'] } )

```

However, AUC values are biased because they vary with the spatial extent used to select the background points.

Hijmans (2012) suggests that one could remove “spatial sorting bias” (the difference between the distance from testing-presence to training-presence and the distance from testing-absence to training-presence points) through “point-wise distance sampling”.
```{r}


```

